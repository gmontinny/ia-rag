ELASTICSEARCH_URL=http://localhost:9200
QDRANT_URL=http://localhost:6333
NEO4J_URL=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Modelo de embeddings padrão (pode sobrescrever):
# Recomendado para domínio jurídico em PT-BR (Transformers)
EMBEDDING_MODEL=ulysses-camara/legal-bert-pt-br

# Autenticação Hugging Face (opcional, necessária para repositórios privados/gated)
# Se você tiver um token do HF, defina aqui para permitir o download de modelos privados:
HUGGINGFACE_HUB_TOKEN=
# Após baixar os arquivos do modelo uma vez, você pode usar apenas arquivos locais (offline):
HF_LOCAL_FILES_ONLY=false

# Forçar backend de embeddings (opcional): hf | st
# Por padrão, o projeto escolhe automaticamente (HF para modelos que não são da org sentence-transformers).
# Use esta variável apenas se precisar forçar um backend específico.
EMB_FORCE_BACKEND=

DATA_DIR=./data
QDRANT_COLLECTION=anvisa_chunks
ELASTIC_INDEX=anvisa_docs
QDRANT_UPSERT_BATCH=256   # tamanho do lote para upsert no Qdrant (ajuste se ocorrer erro de payload > 32MiB)
QDRANT_TIMEOUT=60         # timeout (segundos) para chamadas HTTP ao Qdrant (delete/recreate/upsert)
QDRANT_RETRIES=3          # número de tentativas com backoff em operações do Qdrant

# ===== LLM / RAG =====
# Provedor padrão do LLM: gemini | openai
LLM_PROVIDER=gemini

# Google Gemini
# Defina sua chave da Google AI Studio
GEMINI_API_KEY=
GEMINI_MODEL=gemini-3-pro-preview

# OpenAI (GPT)
# Defina sua chave da OpenAI
OPENAI_API_KEY=
OPENAI_MODEL=gpt-5